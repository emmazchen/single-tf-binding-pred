{
    "model_config":{
        "model_name": "ClassificationTransformer",
        "model_kwargs": {
            "encoder": {
                "n_blocks": 6,
                "src_vocab_size": 5,
                "max_seq_len": 10,
                "d_embedding": 80,
                "ff_d_hidden": 80,
                "n_heads": 4,
                "p_drop": 0.1
            },
            "mlp": {
                "l1": {
                    "out_features": 40
                },
                "l2": {
                    "in_features": 40,
                    "out_features": 30
                },
                "l3": {
                    "in_features": 30,
                    "out_features": 1
                }
            },
            "pad_idx": 0
        }
    },

    "loss_config": {
        "loss_fn": "nn.CrossEntropyLoss"
    },

    "optim_config": {
        "optim_fn": "torch.optim.Adam",
        "optim_kwargs":{
            "lr": 0.0001,
            "betas" : [0.9, 0.999],
            "weight_decay" : 0.0001
        }
    },
    "trainer_config": {
        "max_epochs" : 20,
        "devices" : 1,
        "precision" : 16,
        "log_every_n_steps" : 1
    },
    "batch_size": 30,
    "wandb_project": "tf-pfm-transformer-prob",
    "dryrun": false
}